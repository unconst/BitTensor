{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_top_k_gating(x,\n",
    "                       num_experts,\n",
    "                       train,\n",
    "                       k=2,\n",
    "                       initializer=tf.zeros_initializer(),\n",
    "                       noisy_gating=True,\n",
    "                       noise_epsilon=1e-2,\n",
    "                       name=None):\n",
    "  \"\"\"Noisy top-k gating.\n",
    "  See paper: https://arxiv.org/abs/1701.06538.\n",
    "  Args:\n",
    "    x: input Tensor with shape [batch_size, input_size]\n",
    "    num_experts: an integer\n",
    "    train: a boolean - we only add noise at training time.\n",
    "    k: an integer - number of experts per example\n",
    "    initializer: an initializer\n",
    "    noisy_gating: a boolean\n",
    "    noise_epsilon: a float\n",
    "    name: an optional string\n",
    "  Returns:\n",
    "    gates: a Tensor with shape [batch_size, num_experts]\n",
    "    load: a Tensor with shape [num_experts]\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(name, default_name=\"noisy_top_k_gating\"):\n",
    "    input_size = x.get_shape().as_list()[-1]\n",
    "    w_gate = tf.get_variable(\n",
    "        \"w_gate\", [input_size, num_experts], tf.float32, initializer)\n",
    "    if noisy_gating:\n",
    "      w_noise = tf.get_variable(\"w_noise\",\n",
    "                                [input_size, num_experts], tf.float32,\n",
    "                                initializer)\n",
    "    clean_logits = tf.matmul(x, w_gate)\n",
    "    if noisy_gating:\n",
    "      raw_noise_stddev = tf.matmul(x, w_noise)\n",
    "      noise_stddev = ((tf.nn.softplus(raw_noise_stddev) + noise_epsilon) *\n",
    "                      (tf.to_float(train)))\n",
    "      noisy_logits = clean_logits + (\n",
    "          tf.random_normal(tf.shape(clean_logits)) * noise_stddev)\n",
    "      logits = noisy_logits\n",
    "      if common_layers.should_generate_summaries():\n",
    "        tf.summary.histogram(\"noisy_logits\", noisy_logits)\n",
    "        tf.summary.histogram(\"noise_stddev\", noise_stddev)\n",
    "    else:\n",
    "      logits = clean_logits\n",
    "    top_logits, top_indices = _my_top_k(logits, min(k + 1, num_experts))\n",
    "    # top k logits has shape [batch, k]\n",
    "    top_k_logits = tf.slice(top_logits, [0, 0], [-1, k])\n",
    "    top_k_indices = tf.slice(top_indices, [0, 0], [-1, k])\n",
    "    top_k_gates = tf.nn.softmax(top_k_logits)\n",
    "    # This will be a `Tensor` of shape `[batch_size, n]`, with zeros in the\n",
    "    # positions corresponding to all but the top k experts per example.\n",
    "    gates = _rowwise_unsorted_segment_sum(top_k_gates, top_k_indices,\n",
    "                                          num_experts)\n",
    "    if noisy_gating and k < num_experts:\n",
    "      load = tf.reduce_sum(\n",
    "          _prob_in_top_k(clean_logits, noisy_logits, noise_stddev, top_logits,\n",
    "                         k), 0)\n",
    "    else:\n",
    "      load = _gates_to_load(gates)\n",
    "    if common_layers.should_generate_summaries():\n",
    "      tf.summary.histogram(\"importance\", tf.reduce_sum(gates, 0))\n",
    "      tf.summary.histogram(\"load\", load)\n",
    "    return gates, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "s = tf.Session()\n",
    "\n",
    "    mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
